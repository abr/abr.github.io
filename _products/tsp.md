---
layout: product
theme: theme-blue

title: Time Series Processor
altTitle: Optimal time series edge processor
badge: 2023
img: tsp.png
tagline: Efficient hardware for the revolutionary LMU

pitch: >
    Process speech, language, audio, biosignals, RF signals, network traffic,
    and more at the edge using the lowest power,
    with the fastest response, at the lowest cost,
    with the most privacy.

feature:
  cta:
    text: Contact sales
    link: "mailto:sales@appliedbrainresearch.com"
  features:
    - title: Reduce cloud costs
      icon: /img/icon-cloud.svg
    - title: Reduce CPU and GPU requirements
      icon: /img/icon-coins.svg
    - title: No network required
      icon: /img/icon-wifi.svg
    - title: Give your customers privacy
      icon: /img/icon-privacy.svg
---

Product managers for devices like cars, appliances, and IoT sensors
are faced with 3 sub-optimal options when attempting to process
time-series data for their devices:

1. Process large data in the cloud---PMs incur cloud compute and latency costs
2. Process large data on CPU/GPU---PMs pay $50-$200 and require high power.
3. Process small data at the edge with small chips---PMs are restricted to
   feature-limited, small models.

The Time Series Processor chip (TSP) is a **groundbreaking
addition to the PMs arsenal, allowing for low-cost, power-efficient
processing of large time-series data in a small chip for a low cost**.

Now, all devices can have complex, full-featured AI in devices for
always-on, low-power AI. Full-featured speech and language interfaces
can affordably be designed into everyday devices without an expensive
or inconsistent internet connection.

Devices must be able to interact with their users regardless of the
state of their connection which also saves power, increases response
speed, accuracy and privacy while lowering costs to device makers and
consumers.

This chip is based on the **provably optimal** [Legendre Memory
Unit]({{ site.baseurl }}{% link _products/lmu.md %}).

- Design-ins underway in automotive, healthcare and ioT. Brings
  revolutionary edge AI capabilities to all devices.
- Other first customers in healthcare, consumer electronics.
- **Full speech and natural language processing <10 mW**.
- Production chips expected Q4 2023
- Production chip cost is expected to be <$4 USD. Compare to over $50
  USD for CPU / GPU with memory for full real-time speech recognition.
- **10x to 25x cost advantage over CPU, GPU.**
- **10x to 100x power advantage over existing algorithms computed on
  CPU, GPU.**
- **Algorithmic proof of optimality.**
- Covered by many issued and pending patents.
- Full software stack including AI model design and deployment,
  speech, language, dialog, anomaly and sound scape networks.

First production chip quantities are being allocated now.

Design-in and applications development services available now.

Contact <sales@appliedbrainresearch.com> to get started
revolutionizing your market with the fullest, edge AI features for
your device!
