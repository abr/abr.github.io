---
layout: product
theme: theme-blue

title: Time Series Processor
altTitle: Edge Time Series Processor
badge: 2023
img: tsp.png
tagline: Efficient hardware for the revolutionary LMU

pitch: >
    Process time series including speech, language, audio, biosignals,
    RF signals, network traffic, and more at the edge.
    Our TSP provides extremely low power usage, low latency, and low cost.

feature:
  cta:
    text: Contact sales
    link: "mailto:sales@appliedbrainresearch.com"
  features:
    - title: Reduce cloud costs
      icon: /img/icon-cloud.svg
    - title: Reduce CPU and GPU requirements
      icon: /img/icon-coins.svg
    - title: No network required
      icon: /img/icon-wifi.svg
    - title: Give your customers privacy
      icon: /img/icon-privacy.svg

related:
  - Legendre Memory Units
  - NengoEdge
---

<em>{{ page.pitch }}</em>

The Time Series Processor chip (TSP) is based on a revolutionary
new algorithm for AI signal processing,
the provably **optimal** [Legendre Memory
Unit]({{ site.baseurl }}{% link _products/lmu.md %}) (LMU) architecture.

Currently, product managers for electronics, cars, appliances, and IoT sensors
have 3 options when dealing with time series data in their devices:

1. Process large data in the cloud---PMs incur cloud compute and latency costs.
2. Process large data on CPU/GPU---PMs pay $50-$200 for hardware
   and require significant power.
3. Process small amounts  of data at the edge with small chips---PMs
   are restricted to feature-limited, small models.

The TSP is a **groundbreaking
addition to the PM's arsenal, allowing for low-cost, power-efficient
processing using large AI models for time series data**.

Now, all devices can have complex, full-featured AI.
For example, **full-featured natural speech and language interfaces**
can be affordably designed into everyday devices without an expensive
or inconsistent internet connection.

<iframe width="100%" height="340" src="https://www.youtube-nocookie.com/embed/Fqhy4yzB4Dk" title="In car voice demo video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

The TSP saves power and increases response speed, accuracy, and privacy
while lowering costs to device makers and consumers.

- Design-ins underway in automotive, healthcare and ioT.
- Production chips expected Q4 2023.
- Production chip cost is expected to be <$4 USD. Compares to full CPU/GPU
  with memory for full real-time speech recognition at over $50 USD.
- **10x to 25x** cost advantage over CPU / GPU.
- **10x to 100x** power advantage over existing algorithms computed on
  CPU / GPU.
- Full speech and natural language processing **<10 mW**.
- Full software stack including AI model design and deployment.
  Custom and pre-trained networks available.

First production chip quantities are being allocated now.
Design-in and applications development services are available now.

Contact <sales@appliedbrainresearch.com> to start leading your market
with revolutionary edge AI features for your device!
