---
layout: service

title: LMU apps
tagline: Solve time series problems more accurately and efficiently with LMUs
img: lmu.png
pitch: >
  Are you having trouble solving a time series problem,
  or your LSTM solution isn't cutting it?
  Need to deploy in a situation with a low power budget?
  We'll help you apply LMUs to solve it better and more efficiently.

links:
  - text: LMU product page
    external_url: /products/lmu
  - text: Language modeling using LMUs
    external_url: https://arxiv.org/abs/2110.02402
  - text: NeurIPS 2019 LMU paper
    external_url: https://papers.nips.cc/paper/9689-legendre-memory-units-continuous-time-representation-in-recurrent-neural-networks.pdf
  - text: NeurIPS 2019 Github repo
    external_url: https://github.com/abr/neurips2019
  - text: State of the art psMNIST performance using LMUs in NengoDL
    external_url: https://www.nengo.ai/nengo-dl/examples/lmu.html
  - text: Simple LMU example in Nengo
    external_url: https://www.nengo.ai/nengo/examples/learning/lmu.html
  - text: LMUs on Loihi neuromorphic hardware
    external_url: https://www.nengo.ai/nengo-loihi/examples/lmu.html
  - text: ABR press release (general)
    external_url: /press/2019-12-09-lmu-general
  - text: ABR press release (technical)
    external_url: /press/2019-12-09-lmu-tech
---

<a href="{{ site.baseurl }}{% link _products/lmu.md %}">LMUs</a> have
been proven to generate optimal, compressed representations of
temporal information. This allows their efficient and scale-invariant
representations to be used to solve real world problems better than
alternative approaches, including LSTMs, GRUs, and Transformers. LMUs
can be trained and deployed with traditional deep learning techniques
on hardware you already have, or can be deployed on neuromorphic
hardware or neural accelerators for massive power savings.

We have worked with many clients to develop LMU-based AI systems to
solve their time series problems more accurately and efficiently than
any other solution on the market today. To ensure customers get the
best results, we often start by implementing standard state-of-the-art
techniques first, as a baseline to compare to. We have yet to find a
time series application in which an LMU-based architecture is not the
best option. This is true whether the client is focussed on problems
in health care, manufacturing, cyber security, robotics, predictive
maintenance, financial prediction, sensor data processing, or
speech recognition.

If you have a time series problem that you're struggling with,
let us show you the power of LMUs firsthand.
